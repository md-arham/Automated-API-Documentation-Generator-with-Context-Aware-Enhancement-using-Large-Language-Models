{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14246436,"sourceType":"datasetVersion","datasetId":9089413}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-22T22:11:45.542244Z","iopub.execute_input":"2025-12-22T22:11:45.542572Z","iopub.status.idle":"2025-12-22T22:11:47.284406Z","shell.execute_reply.started":"2025-12-22T22:11:45.542527Z","shell.execute_reply":"2025-12-22T22:11:47.283608Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/api-dataset/api_dataset/train.json\n/kaggle/input/api-dataset/api_dataset/test.json\n/kaggle/input/api-dataset/api_dataset/val.json\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"installing dependencies","metadata":{}},{"cell_type":"code","source":"!pip install -q transformers datasets evaluate rouge_score nltk\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T22:11:47.285958Z","iopub.execute_input":"2025-12-22T22:11:47.286299Z","iopub.status.idle":"2025-12-22T22:11:56.072209Z","shell.execute_reply.started":"2025-12-22T22:11:47.286274Z","shell.execute_reply":"2025-12-22T22:11:56.071542Z"}},"outputs":[{"name":"stdout","text":"  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install -U transformers datasets evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T22:11:56.073329Z","iopub.execute_input":"2025-12-22T22:11:56.073633Z","iopub.status.idle":"2025-12-22T22:12:13.036300Z","shell.execute_reply.started":"2025-12-22T22:11:56.073604Z","shell.execute_reply":"2025-12-22T22:12:13.035555Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\nCollecting transformers\n  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.4.1)\nCollecting datasets\n  Downloading datasets-4.4.2-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.5)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (22.0.0)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\nRequirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.18)\nRequirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\nRequirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.12.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.11.12)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.1rc0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.6.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nDownloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m101.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading datasets-4.4.2-py3-none-any.whl (512 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m512.3/512.3 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: transformers, datasets\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.57.1\n    Uninstalling transformers-4.57.1:\n      Successfully uninstalled transformers-4.57.1\n  Attempting uninstall: datasets\n    Found existing installation: datasets 4.4.1\n    Uninstalling datasets-4.4.1:\n      Successfully uninstalled datasets-4.4.1\nSuccessfully installed datasets-4.4.2 transformers-4.57.3\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"model configs","metadata":{}},{"cell_type":"code","source":"import json\nimport pandas as pd\nfrom datasets import Dataset, DatasetDict\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\nfrom transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\nimport evaluate\nimport numpy as np\nimport nltk\n\n# --- 1. CONFIGURATION ---\nMODEL_CHECKPOINT = \"t5-base\"\nBATCH_SIZE = 8  # T5-base fits 8-16 on a T4 GPU\nMAX_INPUT_LENGTH = 128   # Metadata usually short\nMAX_TARGET_LENGTH = 256  # Descriptions can be longer\nLEARNING_RATE = 3e-4\nEPOCHS = 1\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T22:12:13.037656Z","iopub.execute_input":"2025-12-22T22:12:13.037995Z","iopub.status.idle":"2025-12-22T22:12:55.281427Z","shell.execute_reply.started":"2025-12-22T22:12:13.037946Z","shell.execute_reply":"2025-12-22T22:12:55.280677Z"}},"outputs":[{"name":"stderr","text":"2025-12-22 22:12:32.524620: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1766441552.937654      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1766441553.047277      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1766441554.137576      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766441554.137618      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766441554.137621      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766441554.137623      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# --- 2. LOAD DATASET ---\ndata_files = {\n    \"train\": \"/kaggle/input/api-dataset/api_dataset/train.json\",\n    \"validation\": \"/kaggle/input/api-dataset/api_dataset/val.json\",\n    \"test\": \"/kaggle/input/api-dataset/api_dataset/test.json\"\n}\n\ndef load_json_dataset():\n    train_df = pd.read_json(\"/kaggle/input/api-dataset/api_dataset/train.json\", lines=True)\n    val_df = pd.read_json(\"/kaggle/input/api-dataset/api_dataset/val.json\", lines=True)\n    test_df = pd.read_json(\"/kaggle/input/api-dataset/api_dataset/test.json\", lines=True)\n    \n    return DatasetDict({\n        \"train\": Dataset.from_pandas(train_df),\n        \"validation\": Dataset.from_pandas(val_df),\n        \"test\": Dataset.from_pandas(test_df)\n    })\n\nraw_datasets = load_json_dataset()\nprint(f\"‚úÖ Data Loaded. Train size: {len(raw_datasets['train'])}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T22:12:55.283299Z","iopub.execute_input":"2025-12-22T22:12:55.283897Z","iopub.status.idle":"2025-12-22T22:12:55.465613Z","shell.execute_reply.started":"2025-12-22T22:12:55.283868Z","shell.execute_reply":"2025-12-22T22:12:55.464869Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Data Loaded. Train size: 6341\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"tokensiser and Preprocessing","metadata":{}},{"cell_type":"code","source":"# --- 3. PREPROCESSING (Tokenization) ---\ntokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n\ndef preprocess_function(examples):\n    inputs = [\"document: \" + doc for doc in examples[\"input_text\"]]\n    model_inputs = tokenizer(\n        inputs,\n        max_length=MAX_INPUT_LENGTH,\n        truncation=True\n    )\n\n    labels = tokenizer(\n        text_target=examples[\"target_text\"],\n        max_length=MAX_TARGET_LENGTH,\n        truncation=True\n    )\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T22:12:55.466557Z","iopub.execute_input":"2025-12-22T22:12:55.466832Z","iopub.status.idle":"2025-12-22T22:12:57.364273Z","shell.execute_reply.started":"2025-12-22T22:12:55.466795Z","shell.execute_reply":"2025-12-22T22:12:57.363445Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d7602ac1eb74a129c01afc4e80c0014"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f98069d587f4896a9dd1d095971caf7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbfecbaaf3dd46429c0f42c1220c37e9"}},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"apply tokenization","metadata":{}},{"cell_type":"code","source":"tokenized_datasets = raw_datasets.map(\n    preprocess_function,\n    batched=True\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T22:12:57.365435Z","iopub.execute_input":"2025-12-22T22:12:57.365815Z","iopub.status.idle":"2025-12-22T22:12:58.788834Z","shell.execute_reply.started":"2025-12-22T22:12:57.365775Z","shell.execute_reply":"2025-12-22T22:12:58.788175Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/6341 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ed30057d2324729b8c2a6916d796bf9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/793 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"820a7bdc1b5e46128299679895617182"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/793 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83feb973e30a478c9505cb100bbed1ea"}},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"Evaluation Metrics (BLEU & ROUGE)","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport nltk\nimport evaluate\n\n# Load metrics once to avoid reloading overhead\nrouge_metric = evaluate.load(\"rouge\")\nbleu_metric = evaluate.load(\"bleu\")\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    \n    # 1. Handle Tuple Outputs\n    if isinstance(predictions, tuple):\n        predictions = predictions[0]\n        \n    # 2. Sanitize Predictions & Labels (-100 -> Pad ID)\n    predictions = np.where(predictions != -100, predictions, tokenizer.pad_token_id)\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    \n    # 3. Decode Tokens -> Text\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    \n    # 4. Post-process for ROUGE (Newline after sentences)\n    decoded_preds_clean = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n    decoded_labels_clean = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n    \n    # 5. Compute ROUGE\n    # use_stemmer=True matches standard paper implementations (like gDoc)\n    result = rouge_metric.compute(predictions=decoded_preds_clean, references=decoded_labels_clean, use_stemmer=True)\n    \n    # 6. Compute BLEU\n    # BLEU expects references as a list of lists: [['ref1'], ['ref2']]\n    # Safety: Replace empty strings with \"empty\" to prevent crashes\n    bleu_refs = [[l if l.strip() else \"empty\"] for l in decoded_labels]\n    bleu_preds = [p if p.strip() else \"empty\" for p in decoded_preds]\n    \n    bleu_score = bleu_metric.compute(predictions=bleu_preds, references=bleu_refs)\n    \n    # Add BLEU to results\n    result[\"bleu\"] = bleu_score[\"bleu\"]\n    \n    # 7. Scale to percentages (0.35 -> 35.0) and round\n    return {k: round(v * 100, 4) for k, v in result.items()}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T22:12:58.790977Z","iopub.execute_input":"2025-12-22T22:12:58.791177Z","iopub.status.idle":"2025-12-22T22:13:04.956276Z","shell.execute_reply.started":"2025-12-22T22:12:58.791156Z","shell.execute_reply":"2025-12-22T22:13:04.954869Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21abbd61a4aa485180bfb78f5900f86e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c1092b0e9884e29813c53f051c844e7"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/3583634591.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Load metrics once to avoid reloading overhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mrouge_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rouge\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mbleu_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bleu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/evaluate/loading.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, config_name, module_type, process_id, num_process, cache_dir, experiment_id, keep_in_memory, download_config, download_mode, revision, **init_kwargs)\u001b[0m\n\u001b[1;32m    746\u001b[0m     \"\"\"\n\u001b[1;32m    747\u001b[0m     \u001b[0mdownload_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDownloadMode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_mode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mDownloadMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREUSE_DATASET_IF_EXISTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m     evaluation_module = evaluation_module_factory(\n\u001b[0m\u001b[1;32m    749\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodule_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/evaluate/loading.py\u001b[0m in \u001b[0;36mevaluation_module_factory\u001b[0;34m(path, module_type, revision, download_config, download_mode, force_local_path, dynamic_modules_path, **download_kwargs)\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mConnectionError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             raise FileNotFoundError(\n\u001b[0m\u001b[1;32m    682\u001b[0m                 \u001b[0;34mf\"Couldn't find a module script at {relative_to_absolute_path(combined_path)}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m                 \u001b[0;34mf\"Module '{path}' doesn't exist on the Hugging Face Hub either.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: Couldn't find a module script at /kaggle/working/bleu/bleu.py. Module 'bleu' doesn't exist on the Hugging Face Hub either."],"ename":"FileNotFoundError","evalue":"Couldn't find a module script at /kaggle/working/bleu/bleu.py. Module 'bleu' doesn't exist on the Hugging Face Hub either.","output_type":"error"}],"execution_count":8},{"cell_type":"markdown","source":"Model & Training Arguments","metadata":{}},{"cell_type":"code","source":"import transformers\nprint(transformers.__version__)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T22:13:04.957360Z","iopub.status.idle":"2025-12-22T22:13:04.957704Z","shell.execute_reply.started":"2025-12-22T22:13:04.957555Z","shell.execute_reply":"2025-12-22T22:13:04.957575Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 5. MODEL & TRAINER ---\nmodel = AutoModelForSeq2SeqLM.from_pretrained(MODEL_CHECKPOINT)\n\nargs = Seq2SeqTrainingArguments(\n    output_dir=f\"{MODEL_CHECKPOINT}-finetuned-openapi\",\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=LEARNING_RATE,\n    per_device_train_batch_size=BATCH_SIZE,\n    per_device_eval_batch_size=BATCH_SIZE,\n    weight_decay=0.01,\n    save_total_limit=3,\n    load_best_model_at_end=True,\n    num_train_epochs=EPOCHS,\n    warmup_steps=200,\n    predict_with_generate=True,\n    fp16=True,\n    report_to=\"none\"\n)\n\ndata_collator = DataCollatorForSeq2Seq(\n    tokenizer,\n    model=model\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T22:13:04.958772Z","iopub.status.idle":"2025-12-22T22:13:04.959172Z","shell.execute_reply.started":"2025-12-22T22:13:04.959005Z","shell.execute_reply":"2025-12-22T22:13:04.959032Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model=model,\n    args=args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics\n)\n\n\n# --- 6. TRAIN ---\nprint(\"üöÄ Starting T5 Fine-tuning...\")\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T22:13:04.960358Z","iopub.status.idle":"2025-12-22T22:13:04.960783Z","shell.execute_reply.started":"2025-12-22T22:13:04.960592Z","shell.execute_reply":"2025-12-22T22:13:04.960615Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 7. SAVE MODEL ---\ntrainer.save_model(\"my_t5_api_model\")\nprint(\"‚úÖ Model Saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T22:13:04.961924Z","iopub.status.idle":"2025-12-22T22:13:04.962295Z","shell.execute_reply.started":"2025-12-22T22:13:04.962097Z","shell.execute_reply":"2025-12-22T22:13:04.962122Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 1. Imports & Setup ---\nimport numpy as np\nimport nltk\nimport evaluate\nfrom transformers import (\n    AutoModelForSeq2SeqLM, \n    AutoTokenizer, \n    Seq2SeqTrainer, \n    Seq2SeqTrainingArguments, \n    DataCollatorForSeq2Seq\n)\n\n# Ensure NLTK data is available\nnltk.download(\"punkt\")\n\n# --- 2. Load Metric Objects ---\nprint(\"‚è≥ Loading metrics (ROUGE, BLEU, BERTScore)...\")\nrouge = evaluate.load(\"rouge\")\nbleu = evaluate.load(\"bleu\")\nbertscore = evaluate.load(\"bertscore\")\n\n# --- 3. Load Model & Tokenizer ---\n# UPDATE THIS PATH to your exact checkpoint folder\nMODEL_PATH = \"/kaggle/working/t5-base-finetuned-openapi/checkpoint-397\" \n\nprint(f\"üîÑ Loading model from: {MODEL_PATH}\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(MODEL_PATH)\ntokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n\n# --- 4. Define Compute Metrics Function ---\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    if isinstance(predictions, tuple): \n        predictions = predictions[0]\n    \n    # 1. Replace -100 (ignore index) with pad token\n    predictions = np.where(predictions != -100, predictions, tokenizer.pad_token_id)\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    \n    # 2. Decode to text\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    \n    # 3. Clean Text (Remove extra whitespace)\n    decoded_preds_clean = [pred.strip() for pred in decoded_preds]\n    decoded_labels_clean = [label.strip() for label in decoded_labels]\n\n    # 4. Prepare for ROUGE (Sentence Splitting is standard for ROUGE)\n    decoded_preds_rouge = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in decoded_preds_clean]\n    decoded_labels_rouge = [\"\\n\".join(nltk.sent_tokenize(label)) for label in decoded_labels_clean]\n    \n    # --- CALCULATION ---\n    \n    # A. ROUGE (Lexical Overlap)\n    result = rouge.compute(\n        predictions=decoded_preds_rouge, \n        references=decoded_labels_rouge, \n        use_stemmer=True\n    )\n    \n    # B. BLEU (Precision) - Use Clean Text\n    # BLEU expects references to be a list of lists: [['ref1'], ['ref2']]\n    bleu_refs = [[l] for l in decoded_labels_clean]\n    bleu_score = bleu.compute(predictions=decoded_preds_clean, references=bleu_refs)\n    result[\"bleu\"] = bleu_score[\"bleu\"]\n    \n    # C. BERTScore (Semantic Similarity) - Use Clean Text\n    # lang=\"en\" downloads the correct roberta-large model automatically\n    bert_result = bertscore.compute(\n        predictions=decoded_preds_clean, \n        references=decoded_labels_clean, \n        lang=\"en\"\n    )\n    # We take the mean F1 score of the batch\n    result[\"bertscore_f1\"] = np.mean(bert_result[\"f1\"])\n    \n    # Round metrics for display\n    final_metrics = {k: round(v * 100, 4) for k, v in result.items()}\n    return final_metrics\n\n# --- 5. Setup Trainer for Evaluation ---\nargs = Seq2SeqTrainingArguments(\n    output_dir=\"t5_final_eval_results\",\n    per_device_eval_batch_size=16,  # Lower if you run out of VRAM (BERTScore is heavy)\n    predict_with_generate=True,\n    generation_max_length=128,\n    fp16=True,                     # Speed up inference\n    report_to=\"none\"\n)\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n\n# Use the 'test' dataset you defined earlier\n# Ensure 'tokenized_datasets' is loaded in your environment!\nif 'tokenized_datasets' not in globals():\n    raise ValueError(\"‚ö†Ô∏è Please load your 'tokenized_datasets' before running this script!\")\n\ntester = Seq2SeqTrainer(\n    model=model,\n    args=args,\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics\n)\n\n# --- 6. Run & Print Results ---\nprint(\"üöÄ Running FINAL Benchmark on T5 (ROUGE + BLEU + BERTScore)...\")\n# This might take 3-5 minutes depending on test set size\nmetrics = tester.evaluate(eval_dataset=tokenized_datasets[\"test\"])\n\nprint(\"\\n\" + \"=\"*40)\nprint(\"üèÜ T5-BASE FINAL RESULTS\")\nprint(\"=\"*40)\nprint(f\"ROUGE-1:      {metrics['eval_rouge1']:.2f}\")\nprint(f\"ROUGE-2:      {metrics['eval_rouge2']:.2f}\")\nprint(f\"ROUGE-L:      {metrics['eval_rougeL']:.2f}\")\nprint(\"-\" * 40)\nprint(f\"BLEU:         {metrics['eval_bleu']:.2f}\")\nprint(\"-\" * 40)\nprint(f\"BERTScore F1: {metrics['eval_bertscore_f1']:.2f}\")\nprint(\"=\"*40)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T20:29:11.590999Z","iopub.execute_input":"2025-12-22T20:29:11.591339Z","iopub.status.idle":"2025-12-22T20:30:38.990242Z","shell.execute_reply.started":"2025-12-22T20:29:11.591307Z","shell.execute_reply":"2025-12-22T20:30:38.989290Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"name":"stdout","text":"‚è≥ Loading metrics (ROUGE, BLEU, BERTScore)...\nüîÑ Loading model from: /kaggle/working/t5-base-finetuned-openapi/checkpoint-397\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_55/42003414.py:98: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n  tester = Seq2SeqTrainer(\n","output_type":"stream"},{"name":"stdout","text":"üöÄ Running FINAL Benchmark on T5 (ROUGE + BLEU + BERTScore)...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [25/25 00:52]\n    </div>\n    "},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7505459f94f4f6ca5a01fa9b3dc1fa8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de498f1445fe4de384562be1a637337f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"753b56860114451d8c88b6c9469ee8a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"725971734879482db2bf17ca2e39b779"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d13e2496c256482c82b683129ee8680b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09b79412dfc14492bb7bbf3257bf3c3a"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n========================================\nüèÜ T5-BASE FINAL RESULTS\n========================================\nROUGE-1:      41.54\nROUGE-2:      26.91\nROUGE-L:      39.20\n----------------------------------------\nBLEU:         2.77\n----------------------------------------\nBERTScore F1: 88.97\n========================================\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"pip install bert_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T22:13:04.966720Z","iopub.status.idle":"2025-12-22T22:13:04.967247Z","shell.execute_reply.started":"2025-12-22T22:13:04.967010Z","shell.execute_reply":"2025-12-22T22:13:04.967038Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 6. RUN EVALUATION + EXTRACT EXAMPLES ---\nprint(\"üöÄ Running FINAL Benchmark on T5...\")\nmetrics = tester.evaluate(eval_dataset=tokenized_datasets[\"test\"])\n\n# --- 7. FIXED: Generate 3 Examples for Report ---\nprint(\"\\nüîç Generating 3 Example Predictions...\")\n\n# Fix the label_ids by replacing -100 with pad_token_id BEFORE decoding\ntest_subset = tokenized_datasets[\"test\"].select(range(3))\ntest_results = tester.predict(test_subset)\n\n# üî• FIX: Clean predictions and labels\npredictions_clean = np.where(test_results.predictions != -100, test_results.predictions, tokenizer.pad_token_id)\nlabels_clean = np.where(test_results.label_ids != -100, test_results.label_ids, tokenizer.pad_token_id)\n\n# Decode examples\nexample_preds = tokenizer.batch_decode(predictions_clean, skip_special_tokens=True)\nexample_refs = tokenizer.batch_decode(labels_clean, skip_special_tokens=True)\nexample_inputs = tokenizer.batch_decode(test_subset[\"input_ids\"], skip_special_tokens=True)\n\n# --- 8. DISPLAY RESULTS ---\nprint(\"\\n\" + \"=\"*50)\nprint(\"üèÜ T5-BASE FINAL RESULTS\")\nprint(\"=\"*50)\nprint(f\"ROUGE-1:      {metrics['eval_rouge1']:.2f}\")\nprint(f\"ROUGE-2:      {metrics['eval_rouge2']:.2f}\")\nprint(f\"ROUGE-L:      {metrics['eval_rougeL']:.2f}\")\nprint(\"-\" * 30)\nprint(f\"BLEU:         {metrics['eval_bleu']:.2f}\")\nprint(\"-\" * 30)\nprint(f\"BERTScore F1: {metrics['eval_bertscore_f1']:.2f}\")\nprint(\"=\"*50)\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"üìã EXAMPLE PREDICTIONS (First 3 Test Samples)\")\nprint(\"=\"*70)\nfor i in range(3):\n    print(f\"\\n--- EXAMPLE {i+1} ---\")\n    print(f\"INPUT:   {example_inputs[i]}\")\n    print(f\"PRED:    {example_preds[i].strip()}\")\n    print(f\"REF:     {example_refs[i].strip()}\")\n    print(\"-\" * 50)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T22:13:04.968445Z","iopub.status.idle":"2025-12-22T22:13:04.968880Z","shell.execute_reply.started":"2025-12-22T22:13:04.968709Z","shell.execute_reply":"2025-12-22T22:13:04.968733Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}